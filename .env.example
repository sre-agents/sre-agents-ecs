# ====================================
# LLM envs
# ====================================

# When using ARK's model (e.g., doubao- series), please set this field to be `openai`
# otherwise, reference LiteLLM document: https://docs.litellm.ai/docs/providers
MODEL_PROVIDER=openai

# Default model for agent
LLM=doubao-1-5-pro-256k-250115

# Model's base url and api key
API_BASE_URL=https://ark.cn-beijing.volces.com/api/v3/
API_KEY=


# ====================================
# Evaluation envs
# ====================================

JUDGE_LLM=doubao-1-5-pro-256k-250115
JUDGE_LLM_API_BASE_URL=https://ark.cn-beijing.volces.com/api/v3/
JUDGE_LLM_API_KEY=


# ====================================
# MCP server envs
# ====================================

# MCP server for ECS helper
ECS_MCP_SERVER=


# ====================================
# Embedding envs
# ====================================

# Default model for text embedding
EMBEDDING_LM=doubao-embedding-text-240715

# Depend on the specific embedding model
EMBEDDING_DIM=2560

# Embedding model's base url and api_key
EMBEDDING_API_BASE_URL=https://ark.cn-beijing.volces.com/api/v3/embeddings
EMBEDDING_API_KEY=

# ====================================
# Vector database envs
# ====================================

# Note: fill this field without `http://` or `https://`
OPENSEARCH_HOST= 
OPENSEARCH_PORT=
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=


# ====================================
# Knowledgebase envs
# ====================================

# The number of knowledgebase retrieved items
KB_SEARCH_TOPK=2

# The type of knowledgebase
# - opensearch: use opensearch to store data
# - local: store data in memory
KB_TYPE=local


# ====================================
# Long-term memory envs
# ====================================

# The number of long-term memory retrieved items
LONGTERM_MEM_SEARCH_TOPK=2

# Two modes:
# - useronly: only store user's input
# - global: store user's input and model's response
LONGTERM_MEM_STORAGE_MODE=useronly

# The type of long-term memory
# - opensearch: use opensearch to store data
# - local: store data in memory
LONGTERM_MEM_TYPE=local